# 知识图谱构建技术-刘峤等

> 论文笔记	



[TOC]



## 摘要

- 对知识图谱的定义和内涵进行说明，给出构建知识图谱的技术框架，按输入的知识素材的抽象程度将其划分为三个层次：**信息抽取层**、**知识融合层**、**知识加工层**
- 对每个层次涉及的关键技术的研究现状进行分类说明，揭示KG的奥秘和与相关学科领域的关系
- 对KG构建技术 **当前** 面临的重大挑战和关键问题进行总结

---



## 定义

> 维基百科对KG的词条解释（沿用Google）

​	知识图谱是谷歌用于增强其搜索引擎功能的辅助知识库

> 上述定义从业界发展动态看来过于简单

---

### 本文定义

知识图谱，是结构化的语义知识库，用于以符号形式描述物理世界中的概念及其相互关系，其基本组成单位是“实体-关系-实体”三元组，以及实体及其相关属性-值对，实体间通过关系相互联结，构成网状的知识结构

包含以下三层含义：

- KG本身是一个具有属性的实体通过关系链接而成的网状知识库。从图的角度，KG本质上是一种概念网络，其中节点表示物理世界中的实体（或概念），而实体间的各种语义关系构成网络中的边。 **KG是对物理世界的一种符号表达**
- KG的研究价值，在于，它是构建当前WEB基础之上的一层覆盖网络（overlay network），借助他能够在网页上建立概念之间的链接关系，从而以最小的代价将互联网中积累的信息组织起来，成为可利用的知识。
- KG的应用价值，能够改变现有的信息检索方式
  1. 通过推理实现概念搜索（相对于现在的字符串模糊搜索方式而言）
  2. 以图形化方式向用户展示经过分类整理的结构化知识



## 架构

> KG自身的逻辑结构
>
> 构建KG所采用的技术（体系）架构

### KG的逻辑结构

> 数据层和模式层

#### 数据层

知识以事实（fact）为单位存储在图数据库。

#### 模式层

**模式层在数据层之上**，是KG的核心。在模式层存储的是经过提炼的知识。

**采用本体库来管理知识图谱的模式层，借助本体库对公理、规则和约束条件的支持能力来规范实体、关系以及实体的类型和属性等对象之间的联系**。

本体库在KG中的地位相当于知识库的 **<u>模具</u>**，所以拥有本体库的知识库冗余知识较少。

### 一般技术架构

![](https://raw.githubusercontent.com/Hengnian-Gu/picBed/master/pictures/20190826142127.png)

> 虚线框内为KG的构建过程，也可以说是KG更新的过程
>
> 过程是，从原始数据出发，采用一系列自动或半自动的技术手段，从原始数据中提取出知识要素（即事实）。并将其存入知识库的数据层和模式层的过程，也是一个迭代更新的过程
>
> 每一轮迭代包括三个阶段（摘要中），信息抽取、知识融合、知识加工

#### 构建方式

- 自顶向下

  借助百科类网站等结构化数据源，从高质量的数据中提取本体和模式信息，加入知识库

- 自底向上

  借助一定的技术手段，从公开采集的数据中提取出资源模式，选择其中置信度较高的新模式，经人工审核后加入到知识库中。随着自动知识抽取和加工技术的不断成熟，**目前大多采用自底向上的方式构建**



## 构建技术

> - 信息抽取，即从各种类型的数据源中提取出实体（概念）、属性以及实体间的相互关系，**在此基础上形成本体化的知识表达**
> - 知识融合，获得新知识后，对其进行整合，**以消除矛盾和歧义**，比如某些实体有多种表达，某个特定称谓对应多个不同的实体
> - 知识加工，对于经过融合的新知识，需要进行 **质量评估**（部分需要人工甄别）

### 信息抽取

> 关键问题：如何从异构数据源中自动抽取信息得到候选知识单元
>
> 关键技术：**实体抽取、关系抽取、属性抽取**

#### 实体抽取

> 又称 **命名实体识别 NER**，指从文本数据集中自动识别出命名实体

+ 早期研究主要面向单一领域（特定行业或特定业务），关注如何识别文本中的人名、地名等专有名词和有意义的时间等实体信息

  - Rau 采用启发式算法与人工编写规则相结合的方法，**首次**实现了从文本中自动抽取公司名称的实体抽取原型系统。然后基于规则的方法有明显的局限性，耗费大量人力、可扩展性差、难适应数据变化
  - 采用**统计机器学习**方法辅助解决。Liu等人利用 **K最近邻算法和条件随机场模型**，实现了对Twitter文本数据中实体的识别

  > 上述单纯基于有监督学习的实体抽取方法，在准确率和召回率上都不够理想，且算法性能依赖于训练样本的规模

  + 采用有监督学习和规则（先验知识）相结合的方法。Lin等人采用 **字典辅助下的最大熵算法**，在基于Medline论文摘要的GENIA数据集上取得较好的结果

+ 随着NER技术的发展，开始关注 **开放域（open domain）**的信息抽取问题

  > 需要首先建立一个 **科学完整的命名实体分类体系**
  >
  > 一方面，用于指导算法研究
  >
  > 另一方面， 便于对抽取得到的实体数据进行管理

  - 2002年，Sekine等人提出一个层次结构的命名实体分类体系，将网络中所有命名实体划分为150个分类
  - 2012年，Ling等人借鉴Freebase的实体分类方法，归纳出112种实体类别，**并基于条件随机场模型进行实体边界识别**，最后**采用自适应感知机算法**实现实体的自动分类

> 互联网中的内容是动态变化的，Web 2.0推动了互联网的概念创新，采用人工预定义实体分类体系的方式已经很难适应时代的需要
>
> 而面向开放域的实体抽取和分类技术能够 **较好的解决这一问题**，该方法的基本思想是 **对于任意给定的实体，采用统计机器学习的方法，从目标数据集（通常是网页等文本数据）中抽取出与之具有相似上下文特征的实体**，从而实现 **实体的分类和聚类**

- 该领域面临的主要挑战就是 **如何从给定的少量实体实例中自动发现具有 <u>区分力</u>的模式**

  - Whitelaw等人提出了一种 **迭代扩展实体语料库**的解决方案，基本思路是，根据已知的实体实例进行特征建模，利用该模型对处理海量数据集得到新的命名实体列表，然后针对新实体建模，迭代地生成实体标注语料库

    > 另一种思路是通过搜索引擎的服务器日志获取新出现的命名实体

  - Jain等人提出了一种面向开放域的无监督学习算法。即事先并不给出实体分类，而是 **基于实体的语义特征从搜索日志中识别出命名实体**，然后采用聚类算法对识别出的实体对象进行聚类。

    > 上述技术在搜索引擎技术中得到应用，用于根据用户输入的关键字自动补全信息

#### 关系抽取

> 文本语料经过实体抽取，得到的是一系列离散的命名实体，为了得到语义信息，还需要从 **相关语料**中提取出实体之间的关联关系
>
> 研究关系抽取技术的目的，就是解决 **如何从文本语料中抽取实体间的关系**这一基本问题

- 早期的关系抽取研究方法主要通过 **人工构造语法和语义规则**，采用模式匹配的方式

  > 两点明显的不足：
  >
  > 1. 要求制定规则的人具有良好的语言学造诣，对特定领域有深入理解和认知
  > 2. 规则制定工作量大，难以应付丰富的语言表达风格，难以拓展

- 学术界开始采用统计机器学习方法，通过对实体间关系的模式进行建模，代替预定义的语法和语义规则
  
  - Kambhatla等人利用自然语言中的词法、句法以及语义特征进行实体关系建模，通过 **最大熵方法**成功地实现了不借助规则硬编码地实体关系抽取
- 出现了大量基于特征向量或核函数的有监督学习方法
  
  - 刘克彬等人借助知网（HowNet）提供的本体知识库够在语义核函数，在开放数据集上对ACE定义的6类实体关系进行抽取
- 有监督的学习方法存在明显不足，需要人工标注大量的语料作为训练集，近年研究重点逐渐转向半监督或者无监督学习方式
  - Carlson等人提出一种基于Bookstrap算法的半监督学习方法，能够自动进行实体关系建模
  - 陈立玮等人针对 **弱监督学习中标注数据不完全可靠的问题**，基于Bookstrapping算法设计思想，提出了一种协同训练方法，通过向传统模型中引入N-Gram特征进行协同训练，实现了对弱监督关系抽取模型的强化
  - Zhang等人采用基于实例的无监督学习方法

> 以上研究成果的共同特点是 **需要预先定义实体关系类型，如雇佣关系、整体部分关系以及位置关系等**
>
> 然而在实际应用中，要想定义出一个完美的实体关系分类系统是十分困难的

- 2007年，Banko等人提出了面向开放域的**信息抽取方法框架（open information extraction， OIE）**，发布了 **基于自监督（self-supervised）学习方式的开放信息抽取原型系统（TextRunner）**，该系统采用少量人工标记数据作为训练集，据此得到一个实体关系分类模型，再依据该模型对开放数据进行分类，依据分类结果训练朴素贝叶斯模型来识别“实体-关系-实体”三元组
- 面向开放域的关系抽取技术 **直接利用语料中的关系词汇对实体进行建模**，不需要预先指定关系的分类
  - Wu等人再OIE的基础上，发布了面向开放域信息抽取的WOE系统，该系统利用维基百科网页信息框（infobox）提供的属性信息，自动构造实体关系训练集
  - Fader等人发现TextRunner和WOE中的错误主要是一些无意义或者不合逻辑的实体关系三元组，据此引入 **语法限制条件和字典约束，采用先识别关系指示词，然后再对实体进行识别的策略**
  - Mausam等人针对上述系统无法识别 **非动词性关系**的局限，通过引入 **上下文分析技术**，提出了一个支持非动词性关系抽取的OILLIE系统

> 面向开放域的关系抽取在综合性能指标方面与面向封闭领域的传统方法相比仍有一定的差距
>
> 部分学者提出 **将两者优势结合起来**

- Banko等人提出了一种 **基于条件随机场**的关系抽取模型（**H-CRF**）
  - 当目标数据集中拥有的关系数量不大，而且有预先定义好的实体关系分类模型可用的情况下，采用传统的机器学习算法进行关系抽取
  - 对于没有预先定义好的实体关系模型或者关系数量过多的情况，则采用开放域关系抽取方法
  - 微软StatSnowball模型

> 当前流行的OIE系统在关系抽取方面存在两个主要问题：
>
> 1. 当前研究的重点集中于如何提高二元实体关系（三元组模式）的抽取准确率和召回率，**很少考虑到现实生活中普遍存在的高阶多元实体关系**
> 2. 研究方法大多只关注发掘词汇或词组之间的关系模式，而 **无法实现对隐含语义关系的抽取**

- Alan等人采用N元关系模型对OIE系统进行改造，提出了 **KRAKEN模型**，有效提高OIE系统对多元实体关系的识别能力
- McCallum提出采用 **后期关系推理**的方法，提高OIE系统对隐含实体关系的发现能力

#### 属性抽取

> 属性抽取的目标是从不同信息源中采集特定实体的属性信息，实现对实体属性的完整勾画

- 由于可以 **将实体的属性视为实体与属性值之间的一种名词性关系，因此也可以将属性抽取问题视为关系抽取问题**
  - 郭剑毅等人将人物属性抽取问题转化为实体关系抽取问题，采用 **支持向量机算法** 实现了人物属性抽取与关系预测模型
- 百科类网站提供的半结构化数据是当前实体属性抽取研究的主要数据来源
  - Suchanek等人设计了基于规则和启发式算法的属性抽取算法，能够从Wikipedia和wordNet网页信息框中自动提取属性名和属性值信息，据此得到了扩展性良好的本体知识库（YAGO）
  - 受到YAGO和Freebase项目的启发，DBpedia项目。
- 尽管从百科类网站获取大量实体属性数据，然而这只是人类知识的冰山一角，**大量的实体属性数据隐藏在非结构化的公开数据中，如何从海量非结构化数据中抽取实体属性是值得关注的理论研究问题**

> 两种解决方案：
>
> 1. 基于百科类网站的半结构化数据，通过自动抽取生成训练语料，用于训练实体属性标注模型，然后将其应用于对非结构化数据的实体属性抽取
> 2. 采用数据挖掘的方式直接从文本中挖掘出实体属性与属性值之间的关系模式，据此实现对属性名和属性值在文本中的定位

### 知识融合

> 通过信息抽取，实现了从非结构化和半结构化数据中获取实体、关系以及实体属性信息的目标，然而，这些结果中可能包含大量的冗余和错误信息，数据之间的关系也是扁平化的，缺乏层次性和逻辑性，因此有必要对其进行清理和整合。
>
> 主要包括两部分内容：
>
> 1. 实体链接
> 2. 知识合并

#### 实体链接

> 实体链接（entity linking）是指对于从文本中抽取得到的实体对象，将其链接到知识库中对应的正确实体对象的操作
>
> 基本思想：首先根据给定的 **实体指称项**，从知识库中选出 **一组候选实体对象**，然后 **通过相似度计算将指称项链接到正确的实体关系**。
>
> 早期的实体链接研究仅关注如何将从文本中抽取到的实体链接到知识库，**忽视了位于同一文档的实体之间存在的语义联系**，近年来学术界开始关注利用 **实体的共生关系**。
>
> **同时将多个实体链接到知识库中，称为集成实体链接（collective entity linking）**
>
> - Han等人提出的基于图的集成实体链接方法

##### 实体链接的一般流程

1. 从文本中通过实体抽取得到实体指称项
2. 进行实体消歧和共指消解，判断知识库中的同名实体与之是否代表不同的含义以及知识库中是否存在其他命名实体与之表示相同的含义
3. 在确认知识库中对应的正确实体对象之后，将该实体指称项链接到知识库中对应实体

##### 实体消歧

> 实体消歧（entity disambiguation）是专门用于 **解决同名实体产生歧义问题的技术**。实际语言环境中，经常会遇到 **某个实体指称项对应于多个命名实体对象的问题**，例如李娜（歌手？网球运动员？）

> **聚类法** 是指以实体对象为聚类中心，将所有指向同一目标实体对象的指称项聚集到以该对象为中心的类别下
>
> 聚类法消歧的关键问题：**如何定义实体对象与指称项之间的相似度**

- 空间向量模型（词袋模型）

  取当前语料中实体指称项周边的词构成特征向量，然后利用向量的余弦相似度进行比较，将该指称项聚类到与之最相近的实体指称项集合中

  - Bagga等人在MUC6数据集，该方法的缺点在于没有考虑 **上下文语义信息**，不适用短文本分析

- 语义模型

  与空间向量模型类似，区别在于 **特征向量的构造方法不同**，**语义模型的特征向量不仅包含词袋向量，而且包含一部分语义特征**

  - Pedersen等人采用 **奇异值分解技术**对文本向量空间进行分解，得到给定维度的浅层语义特征，以此与词袋模型相结合

- 社会网络模型

  基本假设：物以类聚，人以群分

  实体指称项很大程度上是由与其相关联的实体所决定的。建模时，首先利用实体间的关系将与之相关的指称项链接起来构成网络，然后利用社会网络分析技术计算该网络中的节点之间的拓扑距离（网络中的节点即实体的指称项），以此来判定指称项之间的相似度

  - Malin等人利用随机漫步模型对演员合作网络数据进行实体消歧

- 百科知识模型

  百科类网站通常会为每个实体（指称项）分配一个单独页面，其中包括指向其他实体页面的超链接，百科知识 模型正是利用这种链接关系来计算实体指称项之间的相似度。

  - Han等人利用维基百科条目之间的关联关系计算实体指称项之间的相似度
  - Bunescu等人以维基百科作为知识库，基于实体所在页面的上下文信息和指称项所在语料的上下文信息，利用词袋模型构造特征向量作为实体链接时进行相似度比较的依据
  - Sen等人进一步采用主题模型作为相似度计算依据
  - Shen等人提出的Linden模型则同时考虑到了文本相似性和主题一致性，基于维基百科和 WordNet 知识库

  > 百科类知识库中的实体数非常有限，此法推广性较差
  >
  > 为了充分利用海量公开数据中包含的实体区分性证据
  >
  > - Li等人基于生成模型提出了一种增量证据挖掘算法，利用与Twitter数据集

实体消歧技术能够帮助搜索引擎更好地理解用户的搜索意图，从而给出更好的上下文推荐结果。

> **重要问题：** 如何对存在歧义的实体进行重要性评估，以确定推荐内容的优先级。
>
> 主要研究思路：为实体赋予 **权重**，用于表示该实体出现的频率或先验概率
>
> - Ratinov等人通过统计维基百科中的实体出现频率以此作为实体推荐时排序的依据
> - Ochs等人借助搜索引擎的关键词日志和DBpedia知识库，构建了一个本体搜索引擎原型系统

##### 共指消解

> 共指消解（entity resolution）技术主要用于解决多个指称项对应于同一个实体对象的问题
>
> 不同的表述：对象对齐（object alignment）、实体匹配（entity matching）、实体同义（entity synonyms）

- 基于自然语言处理的共指消解是**以句法分析为基础**的，代表性方法是Hobbs算法和向心理论

  - Hobbs算法是最早的代词消解算法之一，主要思路是基于句法分析树进行搜索，适用于实体与代词出现的同一句子中的场景，有一定的局限性。早期的Hobbs算法完全基于句法分析（朴素Hobbs算法），后来加入了语义分析沿用至今

  - 向心理论的基本思想：将表达模式（utterance）视为语篇（discourse）的基本组成单元，通过识别表达模式中的实体，可以获得当前和后续语篇中的关注中心（实体），根据语义的局部连贯性和显著性，就可以在语篇中跟踪受关注的实体。

    > 向心理论最初是为了对语篇中关注中心的局部连贯性进行建模
    >
    > 学术界开始尝试在向心理论的基础上，**利用词性标注和语法分析技术**，提高实体消解方法的适用范围和准确性
    >
    > - Lappin等人基于句法分析和词法分析技术提出了消解算法，能够识别语篇中的第三人称代词和反身代词等回指性代词在语篇中回指的对象

- 随着统计机器学习方法被引入该领域

  - McCarthy等人首次将C4.5决策树算法应用于解决共指消解问题
  - Bean等人发现语义背景知识对于构造共指消解算法非常有帮助

- 除了将共指消解问题视为 **分类问题**之外，还可以将其作为 **聚类问题**来求解

  > 聚类法的基本思想是以实体指称项为中心，通过实体聚类实现指称项与实体对象的匹配
  >
  > 关键问题： **如何定义实体之间的相似度测度**

  - Turney基于点互信息（pointwise mutual information， **PMI**）来求解实体所在文档的相似度，用于求解TOEFL和ESL考试中的同义词测试问题
  - Cheng等人通过对搜索引擎的查询和点击记录进行研究，发现可以根据 **用户查询之后的点击行为**对实体进行区分。通过查询和点击建立实体指称项与相关网页URL之间的关联，进而计算出实体指称项之间的 **点击相似度（click similarity）**

> 基于统计机器学习的共指消解方法通常受限于两个问题：
>
> 训练数据的（特征）稀疏性和难以在不同的概念上下文中建立实体关联
>
> - Pantel等人基于Harris提出的分布相似性模型，提出了一个新的实体相似性测度模型，称为 **术语相似度（term similarity）**，借助该模型可以从全局语料中得到所有术语间的统计意义上的相似性，据此可以完成实体合并
> - Chakrabarti等人则将网页点击相似性和文档相似性这两种测度相结合，提出一种新的查询上下文相似性测度（query context similarity），通过在Bing系统上测试
>
> > 上述两种方法均支持并行计算，均采用MapReduce框架

#### 知识合并

> 构建知识图谱时，可以从第三方知识库产品或已有结构化数据中获取知识输入。

- 合并外部知识库

  将外部知识库融合到本地知识库需要处理两个层面的问题：

  1. 数据层的融合，包括实体的指称、属性、关系以及所属类别等，主要问题是 **如何避免实例以及关系的冲突问题**，造成不必要的冗余
  2. 通过模式层的融合，将新得到的本体融入已有的本体库中

  - Mendes等人提出 **开放数据集成框架（linked data integration framework，LDIF）**，用于对LOD知识库产品进行融合，包括四个步骤：
    1. 获取知识
    2. 概念匹配（不同本体库中的概念表达使用的词汇可能不同，需要对概念表达方式进行统一化处理）
    3. 实体匹配（知识库中有些实体含义相同但是具有不同的标识符，需要对这些实体合并处理）
    4. 知识评估（最后一步是对新增知识进行验证和评估，确保知识图谱内容的一致性和准确性）

- 合并关系数据库

  - 将结构化的历史数据融入到知识图谱中，采用资源描述框架**（RDF）**作为数据模型

  > 这一数据转换过程称为 **RDB2RDF**，实质就是将关系数据库数据转换为RDF的三元组数据
  >
  > W3C于2012年推出了两种映射语言标准
  >
  > - Direct Mapping （A direct mapping of relational data to RDF），采用直接映射的方式
  > - R2RML（RDB to RDF mapping language），具有较高的灵活性和可定制性

  - 许多半结构化方式存储（如XML，CSV，JSON等格式）的历史数据也是高质量的知识来源，同样采用RDF数据模型将其合并到知识图谱中
    - XSPARQL 支持从XML格式转化为RDF
    - Datalift 支持从XML和CSV格式转化为RDF

### 知识加工

通过信息抽取，可以从原始语料中提取出实体、关系与属性等知识要素，再经过知识融合，可以消除实体指称项与实体对象之间的歧义，得到一系列 **事实表达**。

然而，事实本身并不等于知识，要想最终获得 **结构化、网络化的知识体系**，还需要经历 **知识加工**的过程

知识加工主要包括三个方面：

- 本体构建
- 知识推理
- 质量评估

#### 本体构建

> 本体（ontology）是对概念进行建模的规范，是描述客观世界的抽象模型，以形式化方式对概念及其之间的联系给出明确的定义。
>
> **本体的最大特点在于它是共享的，本体中反映的知识是一种明确定义的共识**
>
> **内涵定义：本体是同一领域内的不同主体之间进行交流的语义基础**
>
> 本体是树状结构，相邻层次的节点（概念）之间具有严格的**“IsA”**关系，这种单纯的关系有助于知识推理，但却不利于表达概念的多样性
>
> 在知识图谱中，本体位于模式层，用于描述概念层次体系是知识库中知识的概念模板

- 对于特定领域而言，可以采用领域专家和众包的方式人工构建本体，而对于跨领域的全局本体库而言，采用人工方式不仅工作量巨大，而且很难找到符合要求的专家当前主流的全局本体库产品，都是从一些面向特定领域的现有本体库出发，采用 **自动构建技术**扩展得到的

  - 微软发布的 **Probase本体库**采用**数据驱动的自动化构建方法**。利用统计机器学习算法迭代地从网页文本数据中抽取出概念之间的“IsA”关系，然后合并形成概念层次。

    > 数据驱动的自动化本体构建过程包含三个阶段
    >
    > 1. 实体并列关系相似度计算
    > 2. 实体上下位关系抽取
    > 3. 本体的生成
    >
    > - 实体并列关系相似度是用于考察任意给定的2个实体在多大程度上属于同一概念分类的指标测度
    >
    >   1. **模式匹配法**，采用预先定义实体对模式的方式，通过模式匹配取得给定关键字组合在同一语料单位中共同出现的频率，据此计算实体对之间的相似度
    >   2. **分布相似度法**，前提假设是在相似的上下文环境中频繁出现的实体之间具有语义上的相似性。具体计算，首先将每个实体表示成1个N维向量，其中向量的每个维度表示1个预先定义的上下文环境，向量元素值表示该实体出现在各上下文环境中的概率，然后就可以通过求解向量间的相似度，得到实体间的并列关系相似度
    >
    > - 实体上下位关系抽取是用于确定概念之间的隶属（IsA）关系
    >
    >   1. **基于语法模式**（如Hearst模式）抽取IsA实体对。当前主流的信息抽取系统如KnowItAll、TextRunner、NELL等
    >   2. Probase采用基于 **基于语义的迭代抽取技术**，以逐步求精的方式抽取实体上下位关系。
    >
    >   一般利用概率模型判定IsA关系和区分上下位词，通常借助百科类网站提供的概念分类知识来帮助训练模型，以提高算法精度
    >
    > - 本体生成阶段的主要任务是对各层次得到的概念进行聚类，并对其进行语义类的标定
    >
    > 主要集中于 **实体聚类方法**
    >
    > > 主要的挑战在于经过信息抽取得到的 **实体描述非常的简短，缺乏必要的上下文关系，导致多数统计模型不可用**
    > >
    > > - Wang等人利用基于主题进行层次聚类的方法得到本体结构，为解决主题模型不适用于短文本的提问题，提出了一个**基于单词共现网络**（Term co-occurrence network）的主题聚类和 **上位词抽取模型（CATHY）**，实现基于短文本的主题聚类
    > > - Liu等人采用 **贝叶斯模型对实体关键词进行分层聚类**，时间复杂度nlogn

  - 用**跨语言知识链接**的方法构建本体库。Wang等人利用跨语言知识链方法得到的知识对。

#### 知识推理

> 知识推理是指从知识库中已有的实体关系数据出发，经过计算机推理，建立实体间的 **新关联**，从而拓展和丰富知识网络
>

> 能够从现有知识中发现新的知识
>
> 知识推理的对象并不局限于实体间的关系，也可以是实体的属性值、本体的概念层次关系等
>
> 推理方法分为两类：
>
> - 基于逻辑的推理
> - 基于图的推理

- 基于逻辑的推理，主要包括 **一阶谓词逻辑、描述逻辑以及基于规则的推理**

  - 一阶谓词逻辑建立在命题的基础上，命题被分解为个体（individuals）和谓词（predication）两部分。

    个体是指可独立存在的客体，可以是具体事物也可以是抽象概念

    谓词是用来刻画个体的性质及事物关系的词

  - 复杂的实体关系，采用描述逻辑

    描述逻辑（description logic）是一种 **基于对象的知识表示的形式化工具**，是一阶谓词逻辑的子集，它是 **本体语言推理的重要设计基础**

    基于描述逻辑的知识库一般包括TBox（terminology box）与ABox（assertion box）

    - TBox用于描述概念之间和关系之间的关系的公理集合
    - ABox是描述具体事实的公理集合

  - 基于本体的概念层次进行推理时，对象是 **以Web本体语言（OWL）描述的概念**

    利用专门的规则语言（如semantic Web rule language，SWRL）对本体模型添加自定义规则进行功能拓展

    - Lu等人借助SWRL规则向本体库添加实体隐含关系推理规则，据此实现网络服务的匹配机制

- 基于图的推理方法主要 **基于神经网络模型或者Path Ranking算法**

  - Socher等人将知识库中的实体表达为词向量的形式，进而采用神经张量网络模型（neural tensor networks）进行关系推理
  - Path Ranking算法的基本思想是将知识图谱视为 **图**（以实体为节点，以关系或属性为边），从源节点开始，在图上执行随机游走，如果能够通过一个路径到达目标节点，则推测源和目的节点间可能存在关系

> 由于推理得到的知识准确性低、冗余度高，因此将其加入到知识库之前，通常需要进行 **可证明性检查、矛盾性检查、冗余性检查以及独立性检查**
>
> 跨知识库的知识推理也是大趋势

#### 质量评估

> 意义在于，可以对知识的可信度进行量化，通过舍弃置信度较低的知识，可以保障知识库的质量

- 解决知识库之间的冲突问题

  Mendes等人在LDIF框架基础上提出了一种新的质量评估方法（Sieve方法）

- 对REBERB系统的信息抽取质量进行评估

  Fader等人采用人工标注方式对1000个句子中的实体关系三元组进行了标注，以此作为训练集，得到了一个 **逻辑斯蒂回归模型**

### 知识更新

> 知识库的更新包括概念层的更新和数据层的更新

> 知识图谱的内容更新有两种方式：数据驱动下的全面更新和增量更新



## 跨语言知识图谱的构建

## 知识图谱的应用